{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Paushi2003/Paddy_Pest_Disease_Classification/blob/main/plant_disease_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#connect google drive to load training images\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "0jKDsl13rl1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import keras\n",
        "import tensorflow\n",
        "from keras.preprocessing.image  import ImageDataGenerator\n",
        "from keras.layers import Flatten, Dense\n",
        "from keras import layers,models\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
      ],
      "metadata": {
        "id": "WgJhY6eMW10E"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "I have the paddy pest disease classification dataset in my drive.\n",
        "ImageDataGenerator can apply various transformations, such as rotation, flipping, scaling, shearing,\n",
        "and more, to generate new variations of the input images in real-time.\n",
        "This helps the model to generalize better.\n",
        "'''\n",
        "train_datagen = ImageDataGenerator(zoom_range=0.5,shear_range=0.3,rescale=1/255,horizontal_flip=True)\n",
        "train = train_datagen.flow_from_directory(directory='drive/My Drive/paddy-disease-classification/train_images',target_size=(256,256),batch_size=32)\n"
      ],
      "metadata": {
        "id": "dWlOjhNfW82p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Showcasing three images from the dataset\n",
        "'''\n",
        "t_img,label = train.next()\n",
        "def plotImage(imgarr,label):\n",
        "  for im,l in zip(imgarr,label):\n",
        "    plt.figure(figsize=(5,5))\n",
        "    plt.imshow(im)\n",
        "    plt.show()\n",
        "\n",
        "plotImage(t_img[:3],label[:3])"
      ],
      "metadata": {
        "id": "3loQV8-dcYTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "This is a CNN model that contains 12 layers of which 6 are conv2D layers and the other are MaxPooling2D layers.\n",
        "They are stacked one above the other alternatively. I have set the input shape to 256x256.\n",
        "I resized the images previously to 256x256 so I'm using the input shape as 256x256.\n",
        "Instead of relu we can also use tanh, sigmoid, leaky relu and many more.\n",
        "Since ours is a multi-class classification model that contains 10 classes in total, I am usinf softmax at the output layer.\n",
        "At the end of 100th epoch I got nearly 74% accuracy.\n",
        "I have used adam optimizer as that is basically a common optimizer that we use.\n",
        "Other than adam one can use SGD, AdaGrad, AdaDelta, RMSProp and so on.\n",
        "Similarly we have used categorical crossentropy as the loss function.\n",
        "Since this is a multiclass classification, we used categorical crossentropy.\n",
        "'''\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(128, (3, 3), activation='relu', input_shape=(256, 256, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(128 (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu', input_shape=(256, 256, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "])\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(train, epochs=100,steps_per_epoch=100)\n",
        "model.save('model_extended.h5')\n",
        "model.save('model.keras')"
      ],
      "metadata": {
        "id": "V1Bk8nMC7Tm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "In the above cell, I saved the model as model.h5\n",
        "In this cell, I'm loading the model and using some preprocessing techniques to preprocess\n",
        "the input image that we are going to pass as input to our model to predict its class.\n",
        "Since in the model architecture, I provided input dimension to be 256x256, I am reading the image file,\n",
        "converting it into array and then resizing it to 256x256.\n",
        "I am also normalizing the images before passing it into the model.\n",
        "The model returns the output between 0 to 9.\n",
        "I'm using that as index value to retrieve the class of image.\n",
        "'''\n",
        "img = load_img('/content/100042.jpg', target_size=(256, 256))\n",
        "img_array = img_to_array(img)\n",
        "img_array = img_array.reshape((1, 256, 256, 3))\n",
        "img_array = img_array / 255.0\n",
        "predictions = model.predict(img_array)\n",
        "predicted_class_index = predictions.argmax()\n",
        "class_labels = ['bacterial_leaf_blight', 'bacterial_leaf_streak', 'bacterial_panicle_blight','blast','brown_spot','dead_heart','downy_mildew','hispa','normal','tungro' ]  # Replace with your actual class labels\n",
        "predicted_class_label = class_labels[predicted_class_index]\n",
        "print(predicted_class_label)"
      ],
      "metadata": {
        "id": "K9aVaVspZ7rz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}